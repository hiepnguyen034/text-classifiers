{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from allennlp.commands.elmo import ElmoEmbedder\n",
    "from allennlp.modules.elmo import Elmo, batch_to_ids\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('train.csv').fillna('')\n",
    "data=data.drop(['id'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159571, 7)"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.sample(n=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "elmo = ElmoEmbedder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(264, 1024)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = elmo.embed_sentence(data['comment_text'].iloc[0]).mean(axis=0)\n",
    "sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "class get_embedding_data(Dataset):\n",
    "    \n",
    "    def __init__(self,comments,targets, max_len):\n",
    "        self.comments = comments\n",
    "        self.targets = targets\n",
    "        self.max_len = max_len\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.comments)\n",
    "    \n",
    "    def __getitem__(self,i):\n",
    "        comment = str(self.comments.iloc[i])\n",
    "        comment = comment.split()\n",
    "        comment = self.pad_tokens(comment,self.max_len)\n",
    "        \n",
    "        target = self.targets[i]\n",
    "        vectors_in = elmo.embed_sentence(comment).mean(axis=0)\n",
    "        return {'embedding':torch.FloatTensor(vectors_in),\n",
    "                'targets': torch.FloatTensor(target)\n",
    "               }\n",
    "        \n",
    "    @staticmethod\n",
    "    def pad_tokens(sentence, max_len):\n",
    "        if len(sentence)> max_len:\n",
    "            sentence = sentence[:max_len]\n",
    "        while len(sentence) < max_len:\n",
    "            sentence.append('</s>')\n",
    "        return sentence\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(data['comment_text'],data.loc[:,data.columns != 'comment_text'],\n",
    "                                                   test_size=0.01, random_state = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = get_embedding_data(x_train,y_train,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self,embed_dim=1024, num_lstm=2, lstm_hidden=128, num_class=6):\n",
    "        super(LSTMClassifier,self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_lstm = num_lstm\n",
    "        self.lstm_hidden = lstm_hidden\n",
    "        self.num_class = num_class\n",
    "        self.lstm = nn.LSTM(embed_dim,lstm_hidden,num_lstm,batch_first=True)\n",
    "        self.fc = nn.Linear(lstm_hidden, num_class)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        h0 = torch.zeros(self.num_lstm, x.size(0), self.lstm_hidden,device='cuda').requires_grad_()\n",
    "        c0 = torch.zeros(self.num_lstm, x.size(0), self.lstm_hidden,device='cuda').requires_grad_()\n",
    "        \n",
    "        out, (hn, cn) = self.lstm(x,(h0.detach(),c0.detach()))\n",
    "        out =  self.fc(out[:,-1,:])\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(xtrain, ytrain, batch_size = 32, lr =.01, epoches=10):\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    print('training on {}'.format(device))\n",
    "    model = LSTMClassifier()\n",
    "    loss_func =  nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    model = model.train()\n",
    "    model.to(device)\n",
    "    data = get_embedding_data(x_train,y_train,50)\n",
    "    data_loader = DataLoader(data, batch_size=batch_size)\n",
    "    for epoch in range(epoches):\n",
    "        losses = []\n",
    "        for batches in data_loader:\n",
    "            embedding = batches['embedding'].to(device)\n",
    "            target = batches['targets'].to(device)\n",
    "            preds = model(embedding)\n",
    "            loss = loss_func(preds,target)\n",
    "            losses.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        if epoch %5 == 0:\n",
    "            print('loss at epoch {} is {}'.format(epoch+1,np.mean(losses)))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on cuda\n",
      "loss at epoch 1 is 0.15678890450827537\n",
      "loss at epoch 6 is 0.11260779862923007\n"
     ]
    }
   ],
   "source": [
    "model = train_model(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMClassifier(\n",
       "  (lstm): LSTM(1024, 128, num_layers=2, batch_first=True)\n",
       "  (fc): Linear(in_features=128, out_features=6, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_tokens(sentence, max_len):\n",
    "    if len(sentence)> max_len:\n",
    "        sentence = sentence[:max_len]\n",
    "    while len(sentence) < max_len:\n",
    "        sentence.append('</s>')\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for i in range(5000):\n",
    "    sentence = x_train.iloc[i].split()\n",
    "    sentence = pad_tokens(sentence,50)\n",
    "    sentence = elmo.embed_sentence(sentence).mean(axis=0)\n",
    "    sentence = torch.FloatTensor(sentence)\n",
    "    sentence=sentence.unsqueeze(0)\n",
    "    out=model(sentence.cuda())\n",
    "    out = ((out>0.5)*1).squeeze(0)\n",
    "    predictions.append(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = [list(tensor.cpu().numpy()) for tensor in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.array(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = y_train[:5000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 1024)"
      ]
     },
     "execution_count": 630,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = torch.FloatTensor(sentence)\n",
    "sentence=sentence.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 50, 1024])"
      ]
     },
     "execution_count": 632,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [],
   "source": [
    "out=model(sentence.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0], device='cuda:0')"
      ]
     },
     "execution_count": 706,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((out>0.5)*1).squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1], dtype=int64), array([28550,  1150], dtype=int64))"
      ]
     },
     "execution_count": 709,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_true,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1], dtype=int64), array([29285,   415], dtype=int64))"
      ]
     },
     "execution_count": 710,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_pred,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 0.9681818181818181\n",
      "Hamming_loss: 0.031818181818181815\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import hamming_loss, accuracy_score \n",
    "\n",
    "\n",
    "print(\"accuracy_score:\", accuracy_score(y_true.reshape(-1), y_pred.reshape(-1)))\n",
    "print(\"Hamming_loss:\", hamming_loss(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
