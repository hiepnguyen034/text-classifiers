{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0617 09:09:08.459761 11720 file_utils.py:39] PyTorch version 1.5.0 available.\n",
      "I0617 09:09:11.856180 11720 file_utils.py:55] TensorFlow version 2.0.0 available.\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from collections import defaultdict\n",
    "from textwrap import wrap\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.iloc[700:900,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_sentiment(rating):\n",
    "    rating = int(rating)\n",
    "    if rating <= 2:\n",
    "        return 0\n",
    "    elif rating == 3:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "df['sentiment'] = df.score.apply(to_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['negative', 'neutral', 'positive']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.countplot(df.sentiment)\n",
    "plt.xlabel('review sentiment')\n",
    "ax.set_xticklabels(class_names);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRE_TRAINED_MODEL_NAME = 'bert-base-cased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0617 09:11:17.200367 11720 tokenization_utils.py:1022] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at C:\\Users\\Hiep Nguyen/.cache\\torch\\transformers\\5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_txt = 'When was I last outside? I am stuck at home for 2 weeks.'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer.tokenize(sample_txt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['When',\n",
       " 'was',\n",
       " 'I',\n",
       " 'last',\n",
       " 'outside',\n",
       " '?',\n",
       " 'I',\n",
       " 'am',\n",
       " 'stuck',\n",
       " 'at',\n",
       " 'home',\n",
       " 'for',\n",
       " '2',\n",
       " 'weeks',\n",
       " '.']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_ids = tokenizer.convert_tokens_to_ids(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('[SEP]', 102)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.sep_token, tokenizer.sep_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('[CLS]', 101)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.cls_token, tokenizer.cls_token_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tokenizer.encode_plus(\n",
    "  sample_txt,\n",
    "  max_length=32,\n",
    "  add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n",
    "  return_token_type_ids=False,\n",
    "  pad_to_max_length=True,\n",
    "  return_attention_mask=True,\n",
    "  return_tensors='pt',  # Return PyTorch tensors\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userName</th>\n",
       "      <th>userImage</th>\n",
       "      <th>content</th>\n",
       "      <th>score</th>\n",
       "      <th>thumbsUpCount</th>\n",
       "      <th>reviewCreatedVersion</th>\n",
       "      <th>at</th>\n",
       "      <th>replyContent</th>\n",
       "      <th>repliedAt</th>\n",
       "      <th>sortOrder</th>\n",
       "      <th>appId</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>Joan Casals</td>\n",
       "      <td>https://lh3.googleusercontent.com/-Em2ppgdQ6Ug...</td>\n",
       "      <td>On the phone it works perfectly, but now that ...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4.15.9.6</td>\n",
       "      <td>2019-10-17 08:42:43</td>\n",
       "      <td>Hi, that's a little strange, please send us a ...</td>\n",
       "      <td>2019-10-19 15:13:39</td>\n",
       "      <td>newest</td>\n",
       "      <td>com.anydo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>Julieta Correa</td>\n",
       "      <td>https://lh3.googleusercontent.com/a-/AOh14GifZ...</td>\n",
       "      <td>I used this app for a long time. But now, I do...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4.15.9.6</td>\n",
       "      <td>2019-10-16 13:35:15</td>\n",
       "      <td>If you're experiencing issues with your remind...</td>\n",
       "      <td>2019-10-19 13:59:08</td>\n",
       "      <td>newest</td>\n",
       "      <td>com.anydo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>Temp Test</td>\n",
       "      <td>https://lh3.googleusercontent.com/-4BJ-9iC8p8Q...</td>\n",
       "      <td>Working great so far until my Nokia 8.1 was fo...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4.15.9.6</td>\n",
       "      <td>2019-10-15 13:13:05</td>\n",
       "      <td>Hi, due to Android Q limitations pop up notifi...</td>\n",
       "      <td>2019-10-17 07:04:37</td>\n",
       "      <td>newest</td>\n",
       "      <td>com.anydo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>Bharat Gupta</td>\n",
       "      <td>https://lh3.googleusercontent.com/a-/AOh14GhsL...</td>\n",
       "      <td>Too many crashes over the past few months, esp...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4.15.9.6</td>\n",
       "      <td>2019-10-12 15:46:21</td>\n",
       "      <td>Hi, that's odd, please send us a bug report in...</td>\n",
       "      <td>2019-10-16 08:28:03</td>\n",
       "      <td>newest</td>\n",
       "      <td>com.anydo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>Edvinas Masliukovas</td>\n",
       "      <td>https://lh3.googleusercontent.com/a-/AOh14Ghev...</td>\n",
       "      <td>A good app but does not show full month tasks ...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4.15.9.6</td>\n",
       "      <td>2019-10-12 07:38:21</td>\n",
       "      <td>Hi, that sounds a little strange, please send ...</td>\n",
       "      <td>2019-10-16 08:22:17</td>\n",
       "      <td>newest</td>\n",
       "      <td>com.anydo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                userName                                          userImage  \\\n",
       "700          Joan Casals  https://lh3.googleusercontent.com/-Em2ppgdQ6Ug...   \n",
       "701       Julieta Correa  https://lh3.googleusercontent.com/a-/AOh14GifZ...   \n",
       "702            Temp Test  https://lh3.googleusercontent.com/-4BJ-9iC8p8Q...   \n",
       "703         Bharat Gupta  https://lh3.googleusercontent.com/a-/AOh14GhsL...   \n",
       "704  Edvinas Masliukovas  https://lh3.googleusercontent.com/a-/AOh14Ghev...   \n",
       "\n",
       "                                               content  score  thumbsUpCount  \\\n",
       "700  On the phone it works perfectly, but now that ...      3              3   \n",
       "701  I used this app for a long time. But now, I do...      3              0   \n",
       "702  Working great so far until my Nokia 8.1 was fo...      3              4   \n",
       "703  Too many crashes over the past few months, esp...      3              0   \n",
       "704  A good app but does not show full month tasks ...      3              1   \n",
       "\n",
       "    reviewCreatedVersion                   at  \\\n",
       "700             4.15.9.6  2019-10-17 08:42:43   \n",
       "701             4.15.9.6  2019-10-16 13:35:15   \n",
       "702             4.15.9.6  2019-10-15 13:13:05   \n",
       "703             4.15.9.6  2019-10-12 15:46:21   \n",
       "704             4.15.9.6  2019-10-12 07:38:21   \n",
       "\n",
       "                                          replyContent            repliedAt  \\\n",
       "700  Hi, that's a little strange, please send us a ...  2019-10-19 15:13:39   \n",
       "701  If you're experiencing issues with your remind...  2019-10-19 13:59:08   \n",
       "702  Hi, due to Android Q limitations pop up notifi...  2019-10-17 07:04:37   \n",
       "703  Hi, that's odd, please send us a bug report in...  2019-10-16 08:28:03   \n",
       "704  Hi, that sounds a little strange, please send ...  2019-10-16 08:22:17   \n",
       "\n",
       "    sortOrder      appId  sentiment  \n",
       "700    newest  com.anydo          1  \n",
       "701    newest  com.anydo          1  \n",
       "702    newest  com.anydo          1  \n",
       "703    newest  com.anydo          1  \n",
       "704    newest  com.anydo          1  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class get_data(Dataset):\n",
    "    \n",
    "    def __init__(self,reviews,targets, tokenizer, max_len):\n",
    "        self.reviews = reviews\n",
    "        self.targets = targets\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.reviews)\n",
    "    \n",
    "    def __getitem__(self,item):\n",
    "        review = str(self.reviews[item])\n",
    "        target = self.targets[item]\n",
    "        \n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "        review,\n",
    "        add_special_tokens= True,\n",
    "        max_length= self.max_len,\n",
    "        return_token_type_ids = False,\n",
    "        pad_to_max_length = True,\n",
    "        return_attention_mask= True,\n",
    "        return_tensors ='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"review_test\" : review,\n",
    "            \"input_ids\": encoding['input_ids'].flatten(),\n",
    "            \"attention_mask\" : encoding['attention_mask'].flatten(),\n",
    "            'targets': torch.tensor(target,dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(\n",
    "  df,\n",
    "  test_size=0.1,\n",
    "  random_state=2020\n",
    ")\n",
    "\n",
    "df_val, df_test = train_test_split(\n",
    "  df_test,\n",
    "  test_size=0.5,\n",
    "  random_state= 2020\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
    "    \n",
    "    ds = get_data(\n",
    "    reviews = df.content.to_numpy(),\n",
    "    targets = df.sentiment.to_numpy(),\n",
    "    tokenizer = tokenizer,\n",
    "    max_len = max_len\n",
    "    )\n",
    "    \n",
    "    return DataLoader(ds,batch_size=batch_size, num_workers= 0\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "MAX_LEN = 100\n",
    "train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "val_data_loader = create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "test_data_loader = create_data_loader(df_test, tokenizer, MAX_LEN, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0617 09:11:28.652798 11720 configuration_utils.py:265] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at C:\\Users\\Hiep Nguyen/.cache\\torch\\transformers\\b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.9da767be51e1327499df13488672789394e2ca38b877837e52618a67d7002391\n",
      "I0617 09:11:28.652798 11720 configuration_utils.py:301] Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "I0617 09:11:29.149083 11720 modeling_utils.py:650] loading weights file https://cdn.huggingface.co/bert-base-cased-pytorch_model.bin from cache at C:\\Users\\Hiep Nguyen/.cache\\torch\\transformers\\d8f11f061e407be64c4d5d7867ee61d1465263e24085cfa26abf183fdc830569.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2\n"
     ]
    }
   ],
   "source": [
    "bert_model = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_hidden, pooled_output= bert_model(input_ids=encoding['input_ids'], attention_mask=encoding['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.4070,  0.1858, -0.2489,  ..., -0.0298,  0.1574, -0.0787],\n",
       "         [ 0.2521, -0.4902,  0.4746,  ..., -0.3883,  0.2401, -0.1347],\n",
       "         [ 0.0866, -0.0274, -0.5215,  ...,  0.6011, -0.2430,  0.6801],\n",
       "         ...,\n",
       "         [ 0.0907,  0.1219, -0.3152,  ...,  0.0500,  0.0258,  0.2034],\n",
       "         [ 0.0084,  0.2015,  0.0708,  ..., -0.0751,  0.2075, -0.0857],\n",
       "         [ 0.0273,  0.2316,  0.1510,  ..., -0.1111,  0.0845, -0.1100]]],\n",
       "       grad_fn=<NativeLayerNormBackward>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentClassifier(nn.Module):\n",
    "    def __init__(self, n_classes, pretrained):\n",
    "        super().__init__()\n",
    "        self.bert = BertModel.from_pretrained(pretrained)\n",
    "        self.drp = nn.Dropout(p=0.3)\n",
    "        self.fc = nn.Linear(self.bert.config.hidden_size,n_classes)\n",
    "    \n",
    "    def forward(self,x, attention_mask):\n",
    "        _, pooled_output = self.bert(input_ids=x, attention_mask=attention_mask)\n",
    "        x = self.drp(pooled_output)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0616 17:51:53.777407  2112 configuration_utils.py:265] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at C:\\Users\\Hiep Nguyen/.cache\\torch\\transformers\\b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.9da767be51e1327499df13488672789394e2ca38b877837e52618a67d7002391\n",
      "I0616 17:51:53.778405  2112 configuration_utils.py:301] Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "I0616 17:51:53.950988  2112 modeling_utils.py:650] loading weights file https://cdn.huggingface.co/bert-base-cased-pytorch_model.bin from cache at C:\\Users\\Hiep Nguyen/.cache\\torch\\transformers\\d8f11f061e407be64c4d5d7867ee61d1465263e24085cfa26abf183fdc830569.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 86.00 MiB (GPU 0; 3.00 GiB total capacity; 2.05 GiB already allocated; 12.73 MiB free; 2.22 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-170-9919dde53372>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSentimentClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mPRE_TRAINED_MODEL_NAME\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mto\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    441\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 443\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_backward_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    201\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 203\u001b[1;33m             \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    201\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 203\u001b[1;33m             \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    201\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 203\u001b[1;33m             \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    223\u001b[0m                 \u001b[1;31m# `with torch.no_grad():`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 225\u001b[1;33m                     \u001b[0mparam_applied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    226\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mconvert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    439\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mconvert_to_format\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemory_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconvert_to_format\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 441\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    442\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 86.00 MiB (GPU 0; 3.00 GiB total capacity; 2.05 GiB already allocated; 12.73 MiB free; 2.22 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "model = SentimentClassifier(len(class_names),PRE_TRAINED_MODEL_NAME)\n",
    "#model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 101, 1332, 1108,  146, 1314, 1796,  136,  146, 1821, 5342, 1120, 1313,\n",
       "         1111,  123, 2277,  119,  102,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding['input_ids']\n",
    "\n",
    "#out = model(encoding['input_ids'].cuda(), encoding['attention_mask'].cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.argmax(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(data_loader, epochs=10, device ='cpu'):\n",
    "    model = SentimentClassifier(len(class_names),PRE_TRAINED_MODEL_NAME)\n",
    "    model = model.to(device)\n",
    "    optimizer = AdamW(model.parameters(),lr=2e-5, correct_bias=False)\n",
    "    steps = len(train_data_loader) * epochs\n",
    "    \n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, num_warmup_steps=0, num_training_steps= steps)\n",
    "    \n",
    "    loss_func = nn.CrossEntropyLoss().to(device)\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        losses = []\n",
    "        for d in data_loader:\n",
    "            input_ids = d['input_ids'].to(device)\n",
    "            attention_mask = d['attention_mask'].to(device)\n",
    "            targets = d['targets'].to(device)\n",
    "\n",
    "            outputs = model(input_ids,\n",
    "                           attention_mask = attention_mask)\n",
    "            preds = torch.argmax(outputs)\n",
    "            loss = loss_func(outputs,targets)\n",
    "            print(loss)\n",
    "            losses.append(loss.item())\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(),max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "        print('-'*40)\n",
    "        print('loss at epoch {} is {}'.format(epoch,np.mean(losses)))\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0617 10:01:19.640799 11720 configuration_utils.py:265] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at C:\\Users\\Hiep Nguyen/.cache\\torch\\transformers\\b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.9da767be51e1327499df13488672789394e2ca38b877837e52618a67d7002391\n",
      "I0617 10:01:19.642799 11720 configuration_utils.py:301] Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "I0617 10:01:20.129968 11720 modeling_utils.py:650] loading weights file https://cdn.huggingface.co/bert-base-cased-pytorch_model.bin from cache at C:\\Users\\Hiep Nguyen/.cache\\torch\\transformers\\d8f11f061e407be64c4d5d7867ee61d1465263e24085cfa26abf183fdc830569.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0062, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8180, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8943, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9292, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9147, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7970, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8519, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9423, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8198, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7753, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0076, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8583, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8170, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7819, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8377, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7108, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7284, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8697, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5712, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7965, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9091, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6472, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8568, grad_fn=<NllLossBackward>)\n",
      "----------------------------------------\n",
      "loss at epoch 0 is 0.8322143243706744\n",
      "tensor(0.9221, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6592, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9752, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6427, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7352, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7052, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5973, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0068, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7558, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5713, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7342, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7247, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4881, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6488, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4766, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4953, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5405, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4844, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4068, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5190, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3723, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5269, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5500, grad_fn=<NllLossBackward>)\n",
      "----------------------------------------\n",
      "loss at epoch 1 is 0.7321614836869033\n",
      "tensor(0.7907, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2580, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3193, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2407, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2203, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5060, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3773, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8777, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5840, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2934, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3574, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4765, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1330, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1066, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3525, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1264, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0612, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0515, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0415, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1201, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0402, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1752, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0673, grad_fn=<NllLossBackward>)\n",
      "----------------------------------------\n",
      "loss at epoch 2 is 0.5834238870960214\n",
      "tensor(1.7776, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5873, grad_fn=<NllLossBackward>)\n",
      "tensor(1.1243, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0616, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2293, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0192, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0186, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6433, grad_fn=<NllLossBackward>)\n",
      "tensor(1.3544, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9972, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3139, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1779, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0060, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0052, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5538, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0093, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0234, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0054, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0065, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0069, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0039, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0043, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2927, grad_fn=<NllLossBackward>)\n",
      "----------------------------------------\n",
      "loss at epoch 3 is 0.5269352219411698\n",
      "tensor(0.0061, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5711, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0114, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0304, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0035, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0052, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0135, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2501, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1194, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0236, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0075, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0074, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0025, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0027, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0034, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0025, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0022, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0024, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0026, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0477, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0023, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0031, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0018, grad_fn=<NllLossBackward>)\n",
      "----------------------------------------\n",
      "loss at epoch 4 is 0.4486990501921948\n",
      "tensor(0.1457, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1610, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0026, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0021, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0017, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0019, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0020, grad_fn=<NllLossBackward>)\n",
      "tensor(1.2701, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0020, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0016, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0021, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0019, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0018, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0014, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0026, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0013, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0017, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0012, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0015, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0017, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0012, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0010, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0011, grad_fn=<NllLossBackward>)\n",
      "----------------------------------------\n",
      "loss at epoch 5 is 0.3855921904416417\n",
      "tensor(0.0019, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0020, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0016, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0021, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0011, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0019, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0014, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0014, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0012, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0010, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0014, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0018, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0012, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0012, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0013, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0014, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0011, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0010, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0013, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0012, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0012, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0011, grad_fn=<NllLossBackward>)\n",
      "----------------------------------------\n",
      "loss at epoch 6 is 0.3307034721462814\n",
      "tensor(0.0021, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0014, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0011, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0010, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0012, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0014, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0013, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0013, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0012, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0010, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0012, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0010, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0011, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0012, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward>)\n",
      "----------------------------------------\n",
      "loss at epoch 7 is 0.2895006903054309\n",
      "tensor(0.0012, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0013, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0013, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0014, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0010, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0010, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0011, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0010, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0010, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0010, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0012, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0010, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward>)\n",
      "----------------------------------------\n",
      "loss at epoch 8 is 0.2574438516372266\n",
      "tensor(0.0012, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0013, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0012, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0010, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0010, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0011, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0007, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0011, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0009, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0014, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0012, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0008, grad_fn=<NllLossBackward>)\n",
      "----------------------------------------\n",
      "loss at epoch 9 is 0.23179618434236465\n"
     ]
    }
   ],
   "source": [
    "model = train_loop(train_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tokenizer.encode_plus(\n",
    "  'very nice and brilliant and cool',\n",
    "  max_length=32,\n",
    "  add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n",
    "  return_token_type_ids=False,\n",
    "  pad_to_max_length=True,\n",
    "  return_attention_mask=True,\n",
    "  return_tensors='pt',  # Return PyTorch tensors\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2, grad_fn=<NotImplemented>)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(model(encoding['input_ids'],encoding['attention_mask']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
